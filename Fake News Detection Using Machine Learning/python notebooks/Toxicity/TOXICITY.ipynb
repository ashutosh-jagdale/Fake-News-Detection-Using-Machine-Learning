{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "import markdown\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from colorama import Fore, Back, Style, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = [\"TOXICITY\",\n",
    "           \"SEVERE_TOXICITY\",\n",
    "           \"TOXICITY_FAST\",\n",
    "           \"ATTACK_ON_AUTHOR\",\n",
    "           \"ATTACK_ON_COMMENTER\",\n",
    "           \"INCOHERENT\",\n",
    "           \"INFLAMMATORY\",\n",
    "           \"OBSCENE\",\n",
    "           \"OFF_TOPIC\",\n",
    "           \"UNSUBSTANTIAL\",\n",
    "           \"LIKELY_TO_REJECT\"]\n",
    "\n",
    "class Perspective(object):\n",
    "\n",
    "    base_url = \"https://commentanalyzer.googleapis.com/v1alpha1\"\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def score(self, text, tests=[\"TOXICITY\"], context=None, languages=None, do_not_store=False, token=None, text_type=None):\n",
    "        # data validation\n",
    "        # make sure it's a valid test\n",
    "        # TODO: see if an endpoint that has valid types exists\n",
    "        if isinstance(tests, str):\n",
    "            tests = [tests]\n",
    "        if not isinstance(tests, (list, dict)) or tests is None:\n",
    "            raise ValueError(\"Invalid list/dictionary provided for tests\")\n",
    "        if isinstance(tests, list):\n",
    "            new_data = {}\n",
    "            for test in tests:\n",
    "                new_data[test] = {}\n",
    "            tests = new_data\n",
    "        if text_type:\n",
    "            if text_type.lower() == \"html\":\n",
    "                text = remove_html(text)\n",
    "            elif text_type.lower() == \"md\":\n",
    "                text = remove_html(text, md=True)\n",
    "            else:\n",
    "                raise ValueError(\"{0} is not a valid text_type. Valid options are 'html' or 'md'\".format(str(text_type)))\n",
    "\n",
    "        for test in tests.keys():\n",
    "            if test not in allowed:\n",
    "                warnings.warn(\"{0} might not be accepted as a valid test.\".format(str(test)))\n",
    "            for key in tests[test].keys():\n",
    "                if key not in [\"scoreType\", \"scoreThreshhold\"]:\n",
    "                    raise ValueError(\"{0} is not a valid sub-property for {1}\".format(key, test))\n",
    "\n",
    "        # The API will only grade text less than 3k characters long\n",
    "        if len(text) > 3000:\n",
    "            # TODO: allow disassembly/reassembly of >3000char comments\n",
    "            warnings.warn(\"Perspective only allows 3000 character strings. Only the first 3000 characters will be sent for processing\")\n",
    "            text = text[:3000]\n",
    "        new_langs = []\n",
    "        if languages:\n",
    "            for language in languages:\n",
    "                language = language.lower()\n",
    "                if validate_language(language):\n",
    "                    new_langs.append(language)\n",
    "\n",
    "        # packaging data\n",
    "        url = Perspective.base_url + \"/comments:analyze\"\n",
    "        querystring = {\"key\": self.key}\n",
    "        payload_data = {\"comment\": {\"text\": text}, \"requestedAttributes\": {}}\n",
    "        for test in tests.keys():\n",
    "            payload_data[\"requestedAttributes\"][test] = tests[test]\n",
    "        if new_langs != None:\n",
    "            payload_data[\"languages\"] = new_langs\n",
    "        if do_not_store:\n",
    "            payload_data[\"doNotStore\"] = do_not_store\n",
    "        payload = json.dumps(payload_data)\n",
    "        headers = {'content-type': \"application/json\"}\n",
    "        response = requests.post(url,\n",
    "                            data=payload,\n",
    "                            headers=headers,\n",
    "                            params=querystring)\n",
    "        data = response.json()\n",
    "        if \"error\" in data.keys():\n",
    "            raise PerspectiveAPIException(data[\"error\"][\"message\"])\n",
    "        c = Comment(text, [], token)\n",
    "        base = data[\"attributeScores\"]\n",
    "        for test in tests.keys():\n",
    "            score = base[test][\"summaryScore\"][\"value\"]\n",
    "            score_type = base[test][\"summaryScore\"][\"type\"]\n",
    "            a = Attribute(test, [], score, score_type)\n",
    "            for span in base[test][\"spanScores\"]:\n",
    "                beginning = span[\"begin\"]\n",
    "                end = span[\"end\"]\n",
    "                score = span[\"score\"][\"value\"]\n",
    "                score_type = span[\"score\"][\"type\"]\n",
    "                s = Span(beginning, end, score, score_type, c)\n",
    "                a.spans.append(s)\n",
    "            c.attributes.append(a)\n",
    "        return c\n",
    "\n",
    "class Comment(object):\n",
    "    def __init__(self, text, attributes, token):\n",
    "        self.text = text\n",
    "        self.attributes = attributes\n",
    "        self.token = token\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key.upper() not in allowed:\n",
    "            raise ValueError(\"value {0} does not exist\".format(key))\n",
    "        for attr in self.attributes:\n",
    "            if attr.name.lower() == key.lower():\n",
    "                return attr\n",
    "        raise ValueError(\"value {0} not found\".format(key))\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.text\n",
    "\n",
    "    def __repr__(self):\n",
    "        count = 0\n",
    "        num = 0\n",
    "        for attr in self.attributes:\n",
    "            count += attr.score\n",
    "            num += 1\n",
    "        return \"<({0}) {1}>\".format(str(count/num), self.text)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.attributes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "class Attribute(object):\n",
    "    def __init__(self, name, spans, score, score_type):\n",
    "        self.name = name\n",
    "        self.spans = spans\n",
    "        self.score = score\n",
    "        self.score_type = score_type\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.spans[index]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.spans)\n",
    "\n",
    "class Span(object):\n",
    "    def __init__(self, begin, end, score, score_type, comment):\n",
    "        self.begin = begin\n",
    "        self.end = end\n",
    "        self.score = score\n",
    "        self.score_type = score_type\n",
    "        self.comment = comment\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.comment.text[self.begin:self.end]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<({0}) {1}>\".format(self.score, self.comment.text[self.begin:self.end])\n",
    "\n",
    "class PerspectiveAPIException(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Perspective('AIzaSyCsISvXxwxJWC6iU2YmotBRfx9tt3DPzv8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93695754]\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toxicity_scores = []\n",
    "\n",
    "start = time.time()\n",
    "comment = 'this is fucking wrong'\n",
    "if detect(comment) == 'en':\n",
    "        current = time.time()\n",
    "        time.sleep(( 1) - (current - start)) # limit API calls to 1 per second\n",
    "        toxicity = client.score(comment, tests=[\"TOXICITY\"])\n",
    "        \n",
    "        toxicity_scores.append(toxicity[\"TOXICITY\"].score)\n",
    "\n",
    "        \n",
    "        print(toxicity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.5.\n",
      "The scikit-learn version is 0.23.1.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
